{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "def rmse(A, F):\n",
    "    return np.sqrt(np.square(F - A).mean())\n",
    "\n",
    "def show_ts(ts, forecast=None, title=\"Title\", sampling=\"Samplingrate\"):\n",
    "    ax = ts.plot(label = \"Observed\", figsize=(10,3))\n",
    "    if not (forecast is None):\n",
    "        forecast.plot(ax=ax, label='Forecast')\n",
    "        plt.legend()\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Messages/'+sampling)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data into memory\n",
    "dataset_names = [\"avazu\",\"IoT\",\"wiki_de\",\"wiki_en\",\"horton\",\"retailrocket\",\"taxi\",\"alibaba\",\"google\"]\n",
    "sampling_rates = [\"1h\",\"15min\",\"5min\"]\n",
    "\n",
    "datasets = {}  # {dataset_name: {sampling_rate: df}}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    datasets[dataset_name] = {}\n",
    "    for sampling_rate in sampling_rates:\n",
    "        results_statistical = pd.read_csv(f\"results/{dataset_name}_{sampling_rate}_results.csv\", index_col=0, parse_dates=True)\n",
    "        results_ml = pd.read_csv(f\"dl_experiments/results/{dataset_name}_{sampling_rate}_cuda:0_results.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "        df = pd.concat([results_statistical, results_ml[[\"GRU\", \"CNN\"]]], axis=1)\n",
    "        df.name = f\"{dataset_name}_{sampling_rate}\"\n",
    "        datasets[dataset_name][sampling_rate] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avazu\n",
      "\t1h\n",
      "\t\tLASTOBSERVED: 3.53\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_smape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b86472b04b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t\\t{model}: {smape(df.t,df[model]):.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mmodel_smape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_smape' is not defined"
     ]
    }
   ],
   "source": [
    "# Print SMAPE\n",
    "for dataset_name, x in datasets.items():\n",
    "    print(dataset_name)\n",
    "    for sampling_rate, df in x.items():\n",
    "        print(\"\\t\"+sampling_rate)\n",
    "        models = df.columns[1:]\n",
    "        for model in models:\n",
    "            print(f\"\\t\\t{model}: {smape(df.t,df[model]):.2f}\")\n",
    "            model_smape[m] = smape(df.t,df[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=4, nrows=2, sharey=True, figsize=(24,8))\n",
    "axs = [ax for axs_col in axs for ax in axs_col]\n",
    "#f.tight_layout(pad=0)\n",
    "sns.set_theme(style='ticks')\n",
    "            \n",
    "for (dataset_name, x), ax in zip(datasets.items(), axs):\n",
    "    df = x[\"5min\"]\n",
    "    \n",
    "    model_smape = {}\n",
    "    for model in df.columns[1:]:\n",
    "        model_smape[model] = smape(df.t,df[model])\n",
    "    model_smape = pd.DataFrame([model_smape])\n",
    "    #print(model_smape)\n",
    "    \n",
    "    sns.barplot(data=model_smape, ax=ax)\n",
    "    ax.title.set_text(dataset_name)\n",
    "    ax.set(xlabel=\"\")\n",
    "            \n",
    "    #model_smape.plot(ax=ax)\n",
    "    \n",
    "    #ax.title.set_text(dataset_name)\n",
    "    #ax.set(xlabel=\"\")\n",
    "    \n",
    "    #ax.set_xlim(0, 1440 * 7)\n",
    "    \n",
    "    #ax.axvline(1440*5, color=\"k\")\n",
    "\n",
    "    #for idx, _ in x.groupby(\"time\").mean().sort_values(df.name)[:steps].iterrows():\n",
    "    #    ax.axvspan(idx, idx+30, facecolor=\"0.5\", alpha=0.5, lw=0)\n",
    "    \n",
    "    #ticks = range(0, 7*24*60+1, 24*60)\n",
    "    #ax.set_xticks(ticks)\n",
    "    #ax.set_xticks(range(0, 7*24*60+1, 6*60), minor=True)\n",
    "    #ax.set_xticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\", \"Mon\"])\n",
    "\n",
    "#ax.set(xlabel=\"Days of the Week\")\n",
    "#f.text(-0.075, 0.5, \"Carbon intensity (gCO2/kWh)\", ha=\"center\", va=\"center\", rotation=\"vertical\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "f.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.11, 0.96), frameon=False, ncol=len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datasets[\"alibaba\"][\"1h\"]\n",
    "\n",
    "x.t.plot()\n",
    "x.SARIMA.plot()\n",
    "x.Prophet.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=1, nrows=3, sharex=True, figsize=(7,7))\n",
    "f.tight_layout(h_pad=0)\n",
    "\n",
    "palette = sns.color_palette([\"#79869f\", \"#6f83a9\", '#701f57', '#ad1759', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "def results_plot(sampling_rate, ax):\n",
    "    dfs = []\n",
    "    for dataset_name, x in datasets.items():\n",
    "        df = x[sampling_rate]\n",
    "        model_smape = pd.DataFrame([{model: smape(df.t,df[model]) for model in df.columns[1:]}])\n",
    "        model_smape[\"dataset\"] = dataset_name\n",
    "        dfs.append(model_smape)\n",
    "    \n",
    "    d = pd.concat(dfs, ignore_index=True)\n",
    "    d = d.rename(columns={\"LASTOBSERVED\": \"Last\\nobserved\", \"LASTDAY\": \"Last\\nday\", \"SimpleExpSmoothing\": \"SES\", \"ExpSmoothing\": \"TES\"})\n",
    "    d = pd.melt(d, id_vars=[\"dataset\"], var_name=\"algorithm\", value_name=\"SMAPE\")\n",
    "    \n",
    "    if sampling_rate == \"5min\":\n",
    "        d.loc[d[\"algorithm\"] == \"Prophet\", \"SMAPE\"] = np.nan\n",
    "        d.loc[d[\"algorithm\"] == \"SARIMA\", \"SMAPE\"] = np.nan\n",
    "        \n",
    "    if sampling_rate == \"15min\":\n",
    "        d.loc[d[\"algorithm\"] == \"Prophet\", \"SMAPE\"] = np.nan\n",
    "    \n",
    "    means = d.groupby('algorithm').mean()\n",
    "    min_baseline = min(means.loc[\"Last\\nday\"][0], means.loc[\"Last\\nobserved\"][0])\n",
    "    ax.axhline(y=min_baseline, linewidth=1, color=(.5, .5, .5), zorder=0)\n",
    "    \n",
    "    g = sns.barplot(data=d, x=\"algorithm\", y=\"SMAPE\", palette=palette, ax=ax)\n",
    "    ax = g.axes\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(sampling_rate)\n",
    "    \n",
    "    #groupedvalues=df.groupby('day').sum().reset_index()\n",
    "    \n",
    "    #plt.legend(title=\"sampling rate\", loc=\"upper left\", framealpha=1)\n",
    "\n",
    "results_plot(\"1h\", axs[0])\n",
    "results_plot(\"15min\", axs[1])\n",
    "results_plot(\"5min\", axs[2])\n",
    "\n",
    "#f.text(-0.03, 0.5, 'SMAPE', va='center', rotation='vertical')\n",
    "\n",
    "plt.savefig(f\"plots/results_smape.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=1, nrows=3, sharex=True, figsize=(7,7))\n",
    "f.tight_layout(h_pad=0)\n",
    "\n",
    "palette = sns.color_palette([\"#79869f\", \"#6f83a9\", '#701f57', '#ad1759', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "def results_plot(sampling_rate, ax):\n",
    "    dfs = []\n",
    "    for dataset_name, x in datasets.items():\n",
    "        df = x[sampling_rate]\n",
    "        model_smape = pd.DataFrame([{model: smape(df.t,df[model]) for model in df.columns[1:]}])\n",
    "        model_smape[\"dataset\"] = dataset_name\n",
    "        model_smape[\"metric\"] = \"SMAPE\"\n",
    "        dfs.append(model_smape)\n",
    "    for dataset_name, x in datasets.items():\n",
    "        df = x[sampling_rate]\n",
    "        model_smape = pd.DataFrame([{model: rmse(df.t,df[model]) for model in df.columns[1:]}])\n",
    "        model_smape[\"dataset\"] = dataset_name\n",
    "        model_smape[\"metric\"] = \"RMSE\"\n",
    "        dfs.append(model_smape)\n",
    "    \n",
    "    d = pd.concat(dfs, ignore_index=True)\n",
    "    d = d.rename(columns={\"LASTOBSERVED\": \"Last\\nobserved\", \"LASTDAY\": \"Last\\nday\", \"SimpleExpSmoothing\": \"SES\", \"ExpSmoothing\": \"TES\"})\n",
    "    d = pd.melt(d, id_vars=[\"dataset\", \"metric\"], var_name=\"algorithm\", value_name=\"error\")\n",
    "    \n",
    "    if sampling_rate == \"5min\":\n",
    "        d.loc[d[\"algorithm\"] == \"Prophet\", \"error\"] = np.nan\n",
    "        d.loc[d[\"algorithm\"] == \"SARIMA\", \"error\"] = np.nan\n",
    "        \n",
    "    if sampling_rate == \"15min\":\n",
    "        d.loc[d[\"algorithm\"] == \"Prophet\", \"error\"] = np.nan\n",
    "    \n",
    "    means = d.groupby('algorithm').mean()\n",
    "    min_baseline = min(means.loc[\"Last\\nday\"][0], means.loc[\"Last\\nobserved\"][0])\n",
    "    ax.axhline(y=min_baseline, linewidth=1, color=(.5, .5, .5), zorder=0)\n",
    "    \n",
    "    g = sns.barplot(data=d, x=\"algorithm\", y=\"error\", hue=\"metric\", palette=palette, ax=ax)\n",
    "    ax = g.axes\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(sampling_rate)\n",
    "    \n",
    "    #groupedvalues=df.groupby('day').sum().reset_index()\n",
    "    \n",
    "    #plt.legend(title=\"sampling rate\", loc=\"upper left\", framealpha=1)\n",
    "\n",
    "results_plot(\"1h\", axs[0])\n",
    "results_plot(\"15min\", axs[1])\n",
    "results_plot(\"5min\", axs[2])\n",
    "\n",
    "#f.text(-0.03, 0.5, 'SMAPE', va='center', rotation='vertical')\n",
    "\n",
    "plt.savefig(f\"plots/results_rmse.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for dataset_name, x in datasets.items():\n",
    "    df = x[\"5min\"]\n",
    "    model_smape = {}\n",
    "    for model in df.columns[1:]:\n",
    "        model_smape[model] = rmse(df.t,df[model])\n",
    "    model_smape = pd.DataFrame([model_smape])\n",
    "    model_smape[\"dataset\"] = dataset_name\n",
    "    dfs.append(model_smape)\n",
    "\n",
    "d = pd.concat(dfs, ignore_index=True)\n",
    "d = d.rename(columns={\"LASTOBSERVED\": \"Last\\nobserved\", \"LASTDAY\": \"Last\\nday\", \"SimpleExpSmoothing\": \"Single\\nExp\", \"ExpSmoothing\": \"Triple\\nExp\"})\n",
    "d = pd.melt(d, id_vars=[\"dataset\"], var_name=\"algorithm\", value_name=\"SMAPE\")\n",
    "\n",
    "means = d.groupby('algorithm').mean()\n",
    "min_baseline = min(means.loc[\"Last\\nday\"][0], means.loc[\"Last\\nobserved\"][0])\n",
    "ax.axhline(y=min_baseline, linewidth=1, color=(.5, .5, .5), zorder=0)\n",
    "\n",
    "sns.barplot(data=d, x=\"dataset\", y=\"SMAPE\", palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = pd.read_csv(\"results/durations.csv\")\n",
    "# remove invalid Prophet models\n",
    "durations.loc[durations[\"sampling_rate\"] == \"15min\", \"Prophet\"] = np.nan\n",
    "durations.loc[durations[\"sampling_rate\"] == \"5min\", \"Prophet\"] = np.nan\n",
    "durations.loc[durations[\"sampling_rate\"] == \"15min\", \"Prophet_tune\"] = np.nan\n",
    "durations.loc[durations[\"sampling_rate\"] == \"5min\", \"Prophet_tune\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_ml = pd.read_csv(\"dl_experiments/results/durations.csv\").drop(columns=[\"device\"])\n",
    "durations = pd.merge(durations, durations_ml, on=[\"dataset\", \"sampling_rate\"])\n",
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = durations[[\"dataset\", \"sampling_rate\", \"SimpleExpSmoothing\", \"ExpSmoothing\", \"ARIMA_opt\", \"SARIMA_opt\", \"Prophet\", \"GRU_train\", \"CNN_train\"]]\n",
    "d = d.rename(columns={\"SARIMA_opt\": \"SARIMA\", \"ARIMA_opt\": \"ARIMA\", \"SimpleExpSmoothing\": \"SES\", \"ExpSmoothing\": \"TES\", \"GRU_train\": \"GRU\", \"CNN_train\": \"CNN\"})\n",
    "d = pd.melt(d, id_vars=[\"dataset\", \"sampling_rate\"], var_name=\"algorithm\", value_name=\"duration\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.axvspan(xmin=4.5, xmax=7, color=(.9, .9, .9), zorder=-1)\n",
    "#plt.axvline(x=4.5, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=1, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=60, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=60*15, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=3600, color=(.5, .5, .5), zorder=0)\n",
    "\n",
    "g = sns.barplot(data=d, x=\"algorithm\", y=\"duration\", hue=\"sampling_rate\", palette=\"mako\")\n",
    "g.set_yscale(\"log\")\n",
    "ax = g.axes\n",
    "ax.set_yticks([0.001, 0.01, 0.1, 1, 10, 60, 60*15, 3600])\n",
    "ax.set_yticklabels([\"1 ms\", \"10 ms\", \"100 ms\", \"1 s\", \"10 s\", \"1 min\", \"15 min\", \"1 h\"])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"fitting duration\")\n",
    "    \n",
    "plt.legend(title=\"sampling rate\", loc=\"upper left\", framealpha=1)\n",
    "plt.savefig(\"plots/train_duration.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = durations[[\"dataset\", \"sampling_rate\", \"SimpleExpSmoothing_tune\", \"ExpSmoothing_tune\", \"ARIMA_tune\", \"SARIMA_tune\", \"Prophet_tune\", \"GRU_pred\", \"CNN_pred\"]]\n",
    "d = d.rename(columns={\"SARIMA_tune\": \"SARIMA\", \"ARIMA_tune\": \"ARIMA\", \"SimpleExpSmoothing_tune\": \"SES\", \"ExpSmoothing_tune\": \"TES\", \"Prophet_tune\": \"Prophet\", \"GRU_pred\": \"GRU\", \"CNN_pred\": \"CNN\"})\n",
    "d = pd.melt(d, id_vars=[\"dataset\", \"sampling_rate\"], var_name=\"algorithm\", value_name=\"duration\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.axvspan(xmin=4.5, xmax=7, color=(.9, .9, .9), zorder=-1)\n",
    "#plt.axvline(x=4.5, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=1, color=(.5, .5, .5), zorder=0)\n",
    "plt.axhline(y=0.0001, color=(.5, .5, .5), zorder=0)\n",
    "\n",
    "g = sns.barplot(data=d, x=\"algorithm\", y=\"duration\", hue=\"sampling_rate\", palette=\"mako\")\n",
    "g.set_yscale(\"log\")\n",
    "ax = g.axes\n",
    "ax.set_yticks([0.0001, 0.001, 0.01, 0.1, 1, 10])\n",
    "ax.set_yticklabels([\"100 Âµs\", \"1 ms\", \"10 ms\", \"100 ms\", \"1 s\", \"10 s\"])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"tuning & prediction duration\")\n",
    "    \n",
    "plt.legend(title=\"sampling rate\", loc=\"upper left\", framealpha=1)\n",
    "plt.savefig(\"plots/pred_duration.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.read_csv(\"results/google_1h_results.csv\", index_col=0, parse_dates=True).drop(columns=[\"LASTOBSERVED\", \"LASTDAY\"]).plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([\"#000\", '#701f57', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "\n",
    "for dataset_name, x in datasets.items():\n",
    "    df = x[\"1h\"]\n",
    "    df = df.drop(columns=[\"LASTOBSERVED\", \"LASTDAY\", \"SimpleExpSmoothing\"])\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "    ax = plt.gca()\n",
    "    ax.set(xlabel=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([\"#000\", \"#6f83a9\", '#701f57', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "df = datasets[\"retailrocket\"][\"1h\"]\n",
    "df = df.drop(columns=[\"LASTOBSERVED\", \"LASTDAY\"])\n",
    "df = df.rename(columns={\"t\": \"Observed\", \"SimpleExpSmoothing\": \"SES\", \"ExpSmoothing\": \"TES\", \"GRU_train\": \"GRU\", \"CNN_train\": \"CNN\"})\n",
    "df = df[[\"Observed\", \"ARIMA\", \"TES\", \"SARIMA\", \"SES\", \"GRU\", \"Prophet\", \"CNN\"]]\n",
    "f = plt.figure(figsize=(7,4))\n",
    "sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "ax = plt.gca()\n",
    "ax.set(ylabel=\"messages per second\")\n",
    "ax.set(xlabel=\"\")\n",
    "ax.get_legend().remove()\n",
    "f.legend(loc='upper left', bbox_to_anchor=(0.11, 1.03), frameon=False, ncol=4)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# Ticks are a little hacky right now\n",
    "start = df.index[0]\n",
    "xticks = []\n",
    "xticklabels = []\n",
    "for days in range(0, 6, 2):\n",
    "    t = start + timedelta(days=days, hours=1)\n",
    "    xticks.append(t)\n",
    "    xticklabels.append(t.strftime(\"%Y-%m-%d\"))\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "ax.margins(x=0.01)\n",
    "    \n",
    "plt.savefig(\"plots/prediction_retailrocket.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datasets[\"avazu\"][\"1h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([\"#000\", '#701f57', '#e13342', '#f37651']) # , '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "df = datasets[\"google\"][\"1h\"]\n",
    "df = df[[\"t\", \"ExpSmoothing\", \"ARIMA\", \"SARIMA\"]]\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette([\"#79869f\", \"#6f83a9\", '#701f57', '#ad1759', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "palette = sns.color_palette(['#701f57', '#ad1759', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90', \"#000\"])\n",
    "\n",
    "df = datasets[\"wiki_de\"][\"1h\"]\n",
    "df = df[[\"SimpleExpSmoothing\", \"ExpSmoothing\", \"ARIMA\", \"SARIMA\", \"Prophet\", \"GRU\", \"CNN\", \"t\"]]\n",
    "df = df[\"2019-07-17 19:00:00\":\"2019-07-18 19:00:00\"]\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel=\"wiki_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets[\"horton\"][\"1h\"]\n",
    "df = df[[\"t\", \"LASTOBSERVED\", \"ARIMA\", \"CNN\"]]\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel=\"horton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette([\"#79869f\", \"#6f83a9\", '#701f57', '#ad1759', '#e13342', '#f37651', '#4c72b0', '#4a998f', '#68ae90'])\n",
    "\n",
    "palette = sns.color_palette([\"#000\", '#e13342', '#68ae90'])\n",
    "\n",
    "df = datasets[\"wiki_de\"][\"15min\"]\n",
    "df = df[[\"t\", \"ARIMA\", \"CNN\"]]\n",
    "df = df['2019-07-18 00:00:00':'2019-07-19 00:00:00']\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.lineplot(data=df, dashes=False, palette=palette)\n",
    "ax = plt.gca()\n",
    "ax.set(xlabel=\"wiki_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"wiki_de\"][\"15min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for dataset_name, x in datasets.items():\n",
    "    sampling_rate_dfs = []\n",
    "    for sampling_rate, df in x.items():\n",
    "        s = pd.DataFrame([{model: smape(df.t,df[model]) for model in df.columns[1:]}])\n",
    "        sampling_rate_dfs.append(s)\n",
    "    df = pd.concat(sampling_rate_dfs)\n",
    "    df.index = pd.Index(sampling_rates, name=\"sampling rate\")\n",
    "    df[\"dataset\"] = dataset_name\n",
    "    df.set_index(\"dataset\", append=True, inplace=True)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = df.reorder_levels(['sampling rate', 'dataset']).sort_index()\n",
    "df.columns = pd.Index(['Last observation', 'Last day', 'SES', 'TES', 'ARIMA', 'SARIMA', 'Prophet', 'GRU', 'CNN'])\n",
    "\n",
    "#print(df.to_latex(float_format='%.2f'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
